# Tiny ImageNet-200 + CLIP è®­ç»ƒé¡¹ç›®

## ğŸ“ å·²åˆ›å»ºçš„æ–‡ä»¶

1. **tiny_imagenet_dataset.py** - è‡ªå®šä¹‰Datasetç±»
2. **train_clip_imagenet.py** - CLIPè®­ç»ƒè„šæœ¬

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æµ‹è¯•Datasetç±»

```bash
# åœ¨MLç¯å¢ƒä¸­è¿è¡Œ
python tiny_imagenet_dataset.py
```

### 2. å¼€å§‹è®­ç»ƒï¼ˆ50ç±»å­é›†ï¼Œæ¨èï¼‰

```bash
# ä½¿ç”¨50ä¸ªç±»åˆ«å¿«é€Ÿè®­ç»ƒ
python train_clip_imagenet.py --num_classes 50 --epochs 10 --batch_size 32
```

### 3. è®­ç»ƒå®Œæ•´æ•°æ®é›†ï¼ˆ200ç±»ï¼‰

```bash
# ä½¿ç”¨å…¨éƒ¨200ä¸ªç±»åˆ«è®­ç»ƒ
python train_clip_imagenet.py --num_classes 200 --epochs 20 --batch_size 32
```

### 4. å†»ç»“CLIPç¼–ç å™¨ï¼ˆæ›´å¿«è®­ç»ƒï¼‰

```bash
# åªè®­ç»ƒåˆ†ç±»å¤´ï¼Œå†»ç»“CLIPç‰¹å¾æå–å™¨
python train_clip_imagenet.py --num_classes 50 --freeze_encoder --epochs 5
```

## ğŸ“Š æ•°æ®é›†ä¿¡æ¯

- **æ•°æ®é›†**: Tiny ImageNet-200
- **æ€»ç±»åˆ«æ•°**: 200
- **å›¾åƒå°ºå¯¸**: 64Ã—64
- **è®­ç»ƒé›†**: 100,000 å¼ å›¾åƒ (æ¯ç±»500å¼ )
- **éªŒè¯é›†**: 10,000 å¼ å›¾åƒ (æ¯ç±»50å¼ )
- **æµ‹è¯•é›†**: 10,000 å¼ å›¾åƒ (æ— æ ‡ç­¾)

## ğŸ¯ TinyImageNetDataset ç±»ç‰¹æ€§

### ä¸»è¦åŠŸèƒ½

```python
from tiny_imagenet_dataset import TinyImageNetDataset, create_dataloaders

# æ–¹å¼1: ç›´æ¥ä½¿ç”¨Dataset
dataset = TinyImageNetDataset(
    root='g:/Thomas/3_1_project/data/tiny-imagenet-200',
    split='train',  # 'train', 'val', 'test'
    num_classes=50,  # ä½¿ç”¨50ä¸ªç±»åˆ«
    random_seed=42
)

# æ–¹å¼2: ä½¿ç”¨ä¾¿æ·å‡½æ•°åˆ›å»ºDataLoader
train_loader, val_loader, test_loader = create_dataloaders(
    root='g:/Thomas/3_1_project/data/tiny-imagenet-200',
    batch_size=32,
    num_classes=50,
    image_size=64
)
```

### æ”¯æŒçš„å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `root` | str | - | æ•°æ®é›†æ ¹ç›®å½• |
| `split` | str | 'train' | 'train', 'val', 'test' |
| `transform` | Callable | None | å›¾åƒå˜æ¢ |
| `num_classes` | int | 200 | ä½¿ç”¨çš„ç±»åˆ«æ•° (1-200) |
| `random_seed` | int | 42 | éšæœºç§å­ |

### å®ç”¨æ–¹æ³•

```python
# è·å–ç±»åˆ«åç§°
class_name = dataset.get_class_name(label=0)  # "Egyptian cat"

# è·å–WordNet ID
wnid = dataset.get_wnid(label=0)  # "n02124075"

# è·å–æ ·æœ¬
image, label = dataset[0]
```

## ğŸ“ CLIPClassifier ç±»ç‰¹æ€§

### æ¨¡å‹æ¶æ„

```python
from train_clip_imagenet import CLIPClassifier

model = CLIPClassifier(
    num_classes=50,
    clip_model_name="ViT-B/32",  # æˆ– "RN50", "ViT-L/14"
    freeze_encoder=False,  # æ˜¯å¦å†»ç»“CLIPç¼–ç å™¨
    device="cuda"
)
```

### è®­ç»ƒç­–ç•¥

1. **å®Œå…¨å¾®è°ƒ** (freeze_encoder=False)
   - æ›´æ–°CLIPçš„æ‰€æœ‰å‚æ•°
   - éœ€è¦æ›´é•¿æ—¶é—´ï¼Œä½†æ•ˆæœæ›´å¥½
   - æ¨èç”¨äºæœ€ç»ˆè®­ç»ƒ

2. **ç‰¹å¾æå–** (freeze_encoder=True)
   - åªè®­ç»ƒåˆ†ç±»å¤´
   - è®­ç»ƒé€Ÿåº¦å¿«ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
   - æ¨èç”¨äºå¿«é€Ÿå®éªŒ

## ğŸ”§ å‘½ä»¤è¡Œå‚æ•°

```bash
python train_clip_imagenet.py --help
```

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--data_root` | tiny-imagenet-200è·¯å¾„ | æ•°æ®é›†æ ¹ç›®å½• |
| `--num_classes` | 50 | ç±»åˆ«æ•°é‡ |
| `--batch_size` | 32 | æ‰¹æ¬¡å¤§å° |
| `--epochs` | 10 | è®­ç»ƒè½®æ•° |
| `--lr` | 1e-4 | å­¦ä¹ ç‡ |
| `--freeze_encoder` | False | æ˜¯å¦å†»ç»“ç¼–ç å™¨ |
| `--save_dir` | ./checkpoints | æ¨¡å‹ä¿å­˜ç›®å½• |

## ğŸ“ˆ è®­ç»ƒç¤ºä¾‹è¾“å‡º

```
======================================================================
CLIP + Tiny ImageNet-200 è®­ç»ƒ
======================================================================
ç±»åˆ«æ•°: 50
æ‰¹æ¬¡å¤§å°: 32
è®­ç»ƒè½®æ•°: 10
å­¦ä¹ ç‡: 0.0001
å†»ç»“ç¼–ç å™¨: False
è®¾å¤‡: cuda
======================================================================

åŠ è½½æ•°æ®é›†...
âœ“ åŠ è½½ train é›†: 25000 å¼ å›¾åƒ, 50 ä¸ªç±»åˆ«
âœ“ åŠ è½½ val é›†: 2500 å¼ å›¾åƒ, 50 ä¸ªç±»åˆ«
âœ“ åŠ è½½ test é›†: 10000 å¼ å›¾åƒ, 50 ä¸ªç±»åˆ«

åˆ›å»ºæ¨¡å‹...
åŠ è½½CLIPæ¨¡å‹: ViT-B/32...
å¾®è°ƒCLIPå›¾åƒç¼–ç å™¨å‚æ•°

å¼€å§‹è®­ç»ƒ...
======================================================================

Epoch 1/10
----------------------------------------------------------------------
Epoch 1 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [02:15<00:00, loss=2.1234, acc=45.23%]
[Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:12<00:00, loss=1.8567, acc=52.34%]

Epoch 1 ç»“æœ:
  è®­ç»ƒ - Loss: 2.1234, Acc: 45.23%
  éªŒè¯ - Loss: 1.8567, Acc: 52.34%
  å­¦ä¹ ç‡: 0.000100
  âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: 52.34%)
...
```

## ğŸ’¡ å®éªŒå»ºè®®

### å¿«é€Ÿå®éªŒï¼ˆæ¨èå…ˆè¿è¡Œï¼‰
```bash
# 5åˆ†é’Ÿå¿«é€Ÿæµ‹è¯•
python train_clip_imagenet.py \
    --num_classes 10 \
    --epochs 3 \
    --batch_size 64 \
    --freeze_encoder
```

### ä¸­ç­‰è§„æ¨¡å®éªŒ
```bash
# 30-60åˆ†é’Ÿ
python train_clip_imagenet.py \
    --num_classes 50 \
    --epochs 10 \
    --batch_size 32
```

### å®Œæ•´å®éªŒ
```bash
# 2-3å°æ—¶
python train_clip_imagenet.py \
    --num_classes 200 \
    --epochs 20 \
    --batch_size 32 \
    --lr 5e-5
```

## ğŸ“ ä¿å­˜çš„æ¨¡å‹

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¿å­˜åœ¨ `./checkpoints/` ç›®å½•ï¼š

```
checkpoints/
â””â”€â”€ best_model_clip_50class.pth  # 50ç±»æœ€ä½³æ¨¡å‹
```

åŠ è½½æ¨¡å‹ç¤ºä¾‹ï¼š
```python
checkpoint = torch.load('checkpoints/best_model_clip_50class.pth')
model.load_state_dict(checkpoint['model_state_dict'])
print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {checkpoint['val_acc']:.2f}%")
```

## ğŸ¨ è‡ªå®šä¹‰è®­ç»ƒ

å¯ä»¥é€šè¿‡ä¿®æ”¹ä»£ç æ¥å®ç°ï¼š
- ä½¿ç”¨ä¸åŒçš„CLIPæ¨¡å‹ (RN50, ViT-L/14ç­‰)
- è°ƒæ•´æ•°æ®å¢å¼ºç­–ç•¥
- ä½¿ç”¨ä¸åŒçš„ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦
- æ·»åŠ æ›´å¤šçš„åˆ†ç±»å±‚

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **Windowsç³»ç»Ÿ**: å°† `num_workers` è®¾ä¸º 0
2. **å†…å­˜ä¸è¶³**: å‡å° `batch_size`
3. **è®­ç»ƒå¤ªæ…¢**: ä½¿ç”¨ `--freeze_encoder` æˆ–å‡å°‘ `num_classes`
4. **æ˜¾å­˜æº¢å‡º**: å‡å° `batch_size` æˆ–ä½¿ç”¨æ›´å°çš„CLIPæ¨¡å‹

## ğŸ”— ç›¸å…³èµ„æº

- CLIPè®ºæ–‡: https://arxiv.org/abs/2103.00020
- CLIP GitHub: https://github.com/openai/CLIP
- Tiny ImageNet: http://cs231n.stanford.edu/tiny-imagenet-200.zip

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸš€
